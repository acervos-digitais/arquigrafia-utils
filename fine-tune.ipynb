{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read DataSet and confirm objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from functools import partial\n",
    "from PIL import ImageDraw as PImageDraw\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "\n",
    "from dataset_utils.finetune_0915 import FTUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load HF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft0915_ds = load_dataset(\"acervos-digitais/ft-0915\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"val\" not in ft0915_ds:\n",
    "  split = ft0915_ds[\"train\"].train_test_split(0.15, seed=1010)\n",
    "  ft0915_ds[\"train\"] = split[\"train\"]\n",
    "  ft0915_ds[\"val\"] = split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ft0915_ds[\"train\"].features[\"objects\"].feature[\"category\"].names\n",
    "\n",
    "id2label = {index: x for index, x in enumerate(categories, start=0)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model and Image Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"microsoft/conditional-detr-resnet-50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "model = AutoModelForObjectDetection.from_pretrained(\n",
    "  MODEL_NAME,\n",
    "  id2label=id2label,\n",
    "  label2id=label2id,\n",
    "  ignore_mismatched_sizes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test HF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = 11\n",
    "image = ft0915_ds[\"train\"][img_id][\"image\"]\n",
    "annotations = ft0915_ds[\"train\"][img_id][\"objects\"]\n",
    "draw = PImageDraw.Draw(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for box,class_idx in zip(annotations[\"bbox\"], annotations[\"category\"]):\n",
    "  x, y, w, h = tuple(box)\n",
    "  x1, y1 = int(x), int(y)\n",
    "  x2, y2 = int(x + w), int(y + h)\n",
    "\n",
    "  draw.rectangle((x, y, x + w, y + h), outline=\"red\", width=1)\n",
    "  draw.text((x, y), id2label[class_idx], fill=(0,255,0))\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Image transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_batch(examples, transform, image_processor, return_pixel_mask=False):\n",
    "  images = []\n",
    "  annotations = []\n",
    "  for image_id, image, objects in zip(examples[\"image_id\"], examples[\"image\"], examples[\"objects\"]):\n",
    "    image = np.array(image.convert(\"RGB\"))\n",
    "\n",
    "    # apply augmentations\n",
    "    # output = transform(image=image, bboxes=objects[\"bbox\"], category=objects[\"category\"])\n",
    "    images.append(image)\n",
    "\n",
    "    # format annotations in COCO format\n",
    "    formatted_annotations = FTUtils.as_coco(image_id, objects)\n",
    "    annotations.append(formatted_annotations)\n",
    "\n",
    "  # Apply the image processor transformations: resizing, rescaling, normalization\n",
    "  result = image_processor(images=images, annotations=annotations, return_tensors=\"pt\")\n",
    "\n",
    "  if not return_pixel_mask:\n",
    "    result.pop(\"pixel_mask\", None)\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Image transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = partial(transform_batch, transform=None, image_processor=image_processor, return_pixel_mask=True)\n",
    "validation_transform = partial(transform_batch, transform=None, image_processor=image_processor, return_pixel_mask=True)\n",
    "\n",
    "train_ds = ft0915_ds[\"train\"].with_transform(train_transform)\n",
    "val_ds = ft0915_ds[\"val\"].with_transform(validation_transform)\n",
    "test_ds = ft0915_ds[\"test\"].with_transform(validation_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "  data = {}\n",
    "  data[\"pixel_values\"] = torch.stack([x[\"pixel_values\"] for x in batch])\n",
    "  data[\"labels\"] = [x[\"labels\"] for x in batch]\n",
    "  if \"pixel_mask\" in batch[0]:\n",
    "    data[\"pixel_mask\"] = torch.stack([x[\"pixel_mask\"] for x in batch])\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds, collate_fn=collate_fn, batch_size=4, shuffle=True)\n",
    "val_dataloader = DataLoader(val_ds, collate_fn=collate_fn, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detr(pl.LightningModule):\n",
    "  def __init__(self, lr, lr_backbone, weight_decay):\n",
    "    super().__init__()\n",
    "    self.model = AutoModelForObjectDetection.from_pretrained(\n",
    "      MODEL_NAME,\n",
    "      id2label=id2label,\n",
    "      label2id=label2id,\n",
    "      ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    # see https://github.com/PyTorchLightning/pytorch-lightning/pull/1896\n",
    "    self.lr = lr\n",
    "    self.lr_backbone = lr_backbone\n",
    "    self.weight_decay = weight_decay\n",
    "\n",
    "  def forward(self, pixel_values, pixel_mask):\n",
    "    return self.model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
    "\n",
    "  def common_step(self, batch, batch_idx):\n",
    "    pixel_values = batch[\"pixel_values\"]\n",
    "    pixel_mask = batch[\"pixel_mask\"]\n",
    "    labels = [{k: v.to(self.device) for k,v in t.items()} for t in batch[\"labels\"]]\n",
    "\n",
    "    outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)\n",
    "\n",
    "    loss = outputs.loss\n",
    "    loss_dict = outputs.loss_dict\n",
    "\n",
    "    return loss, loss_dict\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    loss, loss_dict = self.common_step(batch, batch_idx)\n",
    "    self.log(\"training_loss\", loss)\n",
    "    for k,v in loss_dict.items():\n",
    "      self.log(\"train_\" + k, v.item())\n",
    "\n",
    "    return loss\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    loss, loss_dict = self.common_step(batch, batch_idx)\n",
    "    self.log(\"validation_loss\", loss)\n",
    "    for k,v in loss_dict.items():\n",
    "      self.log(\"validation_\" + k, v.item())\n",
    "\n",
    "    return loss\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    param_dicts = [\n",
    "          {\"params\": [p for n,p in self.named_parameters() if \"backbone\" not in n and p.requires_grad]},\n",
    "          {\n",
    "              \"params\": [p for n,p in self.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
    "              \"lr\": self.lr_backbone,\n",
    "          },\n",
    "    ]\n",
    "    optimizer = torch.optim.AdamW(param_dicts, lr=self.lr, weight_decay=self.weight_decay)\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    return train_dataloader\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    return val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model:\n",
    "  del model\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Detr(lr=1e-4, lr_backbone=1e-5, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(accelerator=\"gpu\", max_epochs=48, gradient_clip_val=0.1)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_MODEL_NAME = \"acervos-digitais/conditional-detr-resnet-50-ft-0915\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.push_to_hub(OUTPUT_MODEL_NAME)\n",
    "image_processor.push_to_hub(OUTPUT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from os import path\n",
    "from PIL import Image as PImage, ImageDraw as PImageDraw, ImageFont as PImageFont\n",
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "\n",
    "from dataset_utils.finetune_0915 import FTUtils\n",
    "\n",
    "MODEL_NAME = \"acervos-digitais/conditional-detr-resnet-50-ft-0915\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft0915_ds = load_dataset(\"acervos-digitais/ft-0915\")\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForObjectDetection.from_pretrained(\n",
    "  MODEL_NAME,\n",
    "  id2label=FTUtils.ID2LABEL,\n",
    "  label2id=FTUtils.LABEL2ID,\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in list(ft0915_ds[\"test\"])[:10]:\n",
    "  img = r[\"image\"]\n",
    "  iw, ih = img.size\n",
    "  draw = PImageDraw.Draw(img)\n",
    "\n",
    "  inputs = image_processor(images=img, return_tensors=\"pt\")\n",
    "  pixel_values = inputs[\"pixel_values\"].to(\"cuda\")\n",
    "\n",
    "  with torch.no_grad():\n",
    "    outputs = model(pixel_values=pixel_values, pixel_mask=None)\n",
    "\n",
    "  ppo = image_processor.post_process_object_detection(outputs,\n",
    "                                                      target_sizes=[(ih, iw)],\n",
    "                                                      threshold=0.13)[0]\n",
    "\n",
    "  print(\"labels:\", [FTUtils.ID2LABEL[c] for c in r[\"objects\"][\"category\"]])\n",
    "  print(\"pred:\", [FTUtils.ID2LABEL[l.item()] for l in ppo[\"labels\"]])\n",
    "\n",
    "  for l,b in zip(ppo[\"labels\"], ppo[\"boxes\"]):\n",
    "    draw.rectangle(((b[0], b[1]), (b[2], b[3])), outline=(255, 0, 0), width=2)\n",
    "\n",
    "  display(img)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
