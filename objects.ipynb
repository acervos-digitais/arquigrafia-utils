{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "from os import listdir, makedirs, path\n",
    "\n",
    "from PIL import Image as PImage\n",
    "\n",
    "from dominant_colors import get_dominant_colors, resize_PIL\n",
    "\n",
    "IMAGES_IN_PATH = \"../../imgs/arquigrafia\"\n",
    "\n",
    "OUT_PATH = \"./metadata/json/objects\"\n",
    "makedirs(OUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJS = [\n",
    "  {\n",
    "    \"minaret\": 0.25,\n",
    "    \"tower\": 0.6,\n",
    "    \"railing\": 0.4,\n",
    "    \"stair railing\": 0.41,\n",
    "    \"guard railing\": 0.4,\n",
    "    \"table\": 0.45,\n",
    "    \"desk\": 0.25,\n",
    "    \"chair\": 0.24,\n",
    "    \"inclined walkway\": 0.32,\n",
    "    \"sculpture\": 0.4,\n",
    "    \"painting\": 0.4,\n",
    "    \"vertical pillar\": 0.35,\n",
    "    \"stairs\": 0.4,\n",
    "    \"stoop steps\": 0.35,\n",
    "    \"stoop stairs\": 0.35,\n",
    "  },\n",
    "  {\n",
    "    \"window\": 0.2,\n",
    "    \"room door\": 0.25,\n",
    "    \"building door\": 0.22,\n",
    "    \"masonry\": 0.2,\n",
    "\n",
    "    \"concrete wall\": 0.2,\n",
    "    \"exposed concrete\": 0.2,\n",
    "    \"concrete structure\": 0.2,\n",
    "    \"poured concrete\": 0.2,\n",
    "  \n",
    "    \"glass window\": 0.2,\n",
    "    \"glass door\": 0.2,\n",
    "    \"mirror\": 0.2,\n",
    "  },\n",
    "  {\n",
    "    \"wood fence\": 0.3,\n",
    "    \"wood railing\": 0.35,\n",
    "    \"wood pilar\": 0.3,\n",
    "    \"wood door\": 0.21,\n",
    "    \"wood board\": 0.21,\n",
    "\n",
    "    \"metal fence\": 0.4,\n",
    "    \"metal railing\": 0.22,\n",
    "    \"wrought\": 0.2,\n",
    "  },\n",
    "  {\n",
    "    \"tree\": 0.2,\n",
    "    \"grass\": 0.2,\n",
    "    \"shrub\": 0.2,\n",
    "    \"bush\": 0.2,\n",
    "    \"flower\": 0.2,\n",
    "    \"vegetation\": 0.2,\n",
    "    \"greenery\": 0.2,\n",
    "  }\n",
    "]\n",
    "\n",
    "LABEL2LABEL = {\n",
    "  \"minaret\": \"tower\",\n",
    "  \"stair railing\": \"railing\",\n",
    "  \"guard railing\": \"railing\",\n",
    "  \"stoop steps\": \"stairs\",\n",
    "  \"stoop stairs\": \"stairs\",\n",
    "  \"desk\": \"table\",\n",
    "  \"room door\": \"building door\",\n",
    "\n",
    "  \"exposed concrete\": \"concrete wall\",\n",
    "  \"concrete structure\": \"concrete wall\",\n",
    "  \"poured concrete\": \"concrete wall\",\n",
    "\n",
    "  \"glass window\": \"mirror\",\n",
    "  \"glass door\": \"mirror\",\n",
    "\n",
    "  \"wood railing\": \"wood fence\",\n",
    "  \"wood pilar\":\"wood fence\",\n",
    "  \"wood door\": \"wood fence\",\n",
    "  \"wood board\": \"wood fence\",\n",
    "\n",
    "  \"metal fence\": \"wrought\",\n",
    "  \"metal railing\": \"wrought\",\n",
    "\n",
    "  \"tree\": \"greenery\",\n",
    "  \"grass\": \"greenery\",\n",
    "  \"shrub\": \"greenery\",\n",
    "  \"bush\": \"greenery\",\n",
    "  \"flower\": \"greenery\",\n",
    "  \"vegetation\": \"greenery\",\n",
    "}\n",
    "\n",
    "OBJS_LABELS_IN = [sorted(o.keys()) for o in OBJS]\n",
    "OBJS_LABELS_OUT = [[LABEL2LABEL.get(l, l) for l in oli] for oli in OBJS_LABELS_IN]\n",
    "OBJS_THOLDS = [[OBJS[i][k] for k in oli] for i,oli in enumerate(OBJS_LABELS_IN)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Owlv2Processor, Owlv2ForObjectDetection\n",
    "\n",
    "OBJ_TARGET_SIZE = torch.Tensor([500, 500])\n",
    "OBJ_MODEL = \"google/owlv2-base-patch16-ensemble\"\n",
    "\n",
    "obj_model = Owlv2ForObjectDetection.from_pretrained(OBJ_MODEL).to(\"cuda\")\n",
    "obj_processor = Owlv2Processor.from_pretrained(OBJ_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_px_to_pct(box, img_w, img_h, model_dims):\n",
    "  scale_factor = torch.tensor([max(img_w, img_h) / img_w , max(img_w, img_h) / img_h])\n",
    "  return [round(x, 4) for x in (box.cpu().reshape(2, -1) / model_dims * scale_factor).reshape(-1).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_object_detection(img, obj_labels_in, obj_labels_out, obj_tholds):\n",
    "  input = obj_processor(text=obj_labels_in, images=img, return_tensors=\"pt\").to(\"cuda\")\n",
    "  with torch.no_grad():\n",
    "    obj_out = obj_model(**input)\n",
    "\n",
    "  res = obj_processor.post_process_object_detection(outputs=obj_out, target_sizes=[OBJ_TARGET_SIZE])\n",
    "  slbs = zip(res[0][\"scores\"], res[0][\"labels\"], res[0][\"boxes\"])\n",
    "  iw, ih = img.size\n",
    "\n",
    "  # filter if box \"too large\" or \"too small\"\n",
    "  def good_thold_and_size(s, l, b):\n",
    "    box_pct = box_px_to_pct(b, iw, ih, OBJ_TARGET_SIZE)\n",
    "    box_width = box_pct[2] - box_pct[0]\n",
    "    box_height = box_pct[3] - box_pct[1]\n",
    "    good_min = box_width > 0.05 and box_height > 0.05\n",
    "    good_max = box_width < 0.8 or box_height < 0.8\n",
    "    return good_min and good_max and s > obj_tholds[l.item()]\n",
    "\n",
    "  detected_objs = [{\"score\": s, \"label\": obj_labels_out[l.item()], \"box\": box_px_to_pct(b, iw, ih, OBJ_TARGET_SIZE)} for s,l,b in slbs if good_thold_and_size(s, l, b)]\n",
    "\n",
    "  # only keep the box with highest score per object\n",
    "  detected_objs_boxes = {}\n",
    "  high_score = {}\n",
    "\n",
    "  for o in detected_objs:\n",
    "    ol = o[\"label\"]\n",
    "    if (ol not in detected_objs_boxes) or (o[\"score\"] > high_score[ol]):\n",
    "      detected_objs_boxes[ol] = o[\"box\"]\n",
    "      high_score[ol] = o[\"score\"]\n",
    "\n",
    "  return detected_objs_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "input_files = sorted([f for f in listdir(IMAGES_IN_PATH) if f.endswith(\"jpg\")])\n",
    "\n",
    "for io_file in input_files[:4096]:\n",
    "  input_file_path = path.join(IMAGES_IN_PATH, io_file)\n",
    "  output_file_path = path.join(OUT_PATH, io_file.replace(\".jpg\", \".json\"))\n",
    "\n",
    "  if path.isfile(output_file_path):\n",
    "    continue\n",
    "\n",
    "  if int(io_file.replace(\".jpg\", \"\")) % 50 == 0:\n",
    "    print(IMAGES_IN_PATH, io_file)\n",
    "\n",
    "  image = PImage.open(input_file_path).convert(\"RGB\")\n",
    "\n",
    "  rgb_by_count, rgb_by_hls = get_dominant_colors(resize_PIL(image))\n",
    "\n",
    "  image_data = {}\n",
    "\n",
    "  image_data[\"boxes\"] = {}\n",
    "  for i in range(0, len(OBJS_LABELS_IN)):\n",
    "    obj_boxes = run_object_detection(image, OBJS_LABELS_IN[i], OBJS_LABELS_OUT[i], OBJS_THOLDS[i])\n",
    "    image_data[\"boxes\"] = image_data[\"boxes\"] | obj_boxes\n",
    "\n",
    "  image_data[\"dominant_color\"] = {\n",
    "    \"by_count\": [int(v) for v in rgb_by_count[0]],\n",
    "    \"by_hue\": [int(v) for v in rgb_by_hls[0]],\n",
    "    \"palette\": [[int(v) for v in c] for c in rgb_by_hls[:4]],\n",
    "  }\n",
    "\n",
    "  with open(output_file_path, \"w\", encoding=\"utf-8\") as of:\n",
    "    json.dump(image_data, of, sort_keys=True, separators=(',',':'), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Process: Create output json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from export_utils import export_objs_caps\n",
    "\n",
    "OBJECTS_PATH = \"./metadata/json/objects\"\n",
    "CAPTIONS_PATH = \"./metadata/json/captions\"\n",
    "OBJECTS_DB_FILE_PATH = \"./metadata/json/objects.json\"\n",
    "\n",
    "export_objs_caps(OBJECTS_PATH, CAPTIONS_PATH, OBJECTS_DB_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Process: Create separate json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from export_utils import export_by_keys\n",
    "\n",
    "OBJECTS_PATH = \"./metadata/json/objects\"\n",
    "\n",
    "keys = [\"binaries\", \"boxes\"]\n",
    "export_by_keys(OBJECTS_PATH, keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJECTS_DB_FILE_PATH = \"./metadata/json/objects.json\"\n",
    "IMAGES_PATH = \"../../imgs/arquigrafia\"\n",
    "\n",
    "LABEL2LABEL = {\n",
    "  \"tower\": \"chimney/tower\",\n",
    "  \"railing\": \"railing/banister\",\n",
    "  \"inclined walkway\": \"ramp\",\n",
    "  \"stairs\": \"stairs\",\n",
    "  \"table\": \"table\",\n",
    "  \"building door\": \"door\",\n",
    "  \"concrete wall\": \"concrete\",\n",
    "  \"masonry\": \"masonry\",\n",
    "  \"mirror\": \"glass\",\n",
    "  \"wood fence\": \"wood\",\n",
    "  \"wrought\": \"metal\",\n",
    "  \"greenery\": \"vegetation\",\n",
    "  \"chair\": \"chair\",\n",
    "  \"painting\": \"painting\",\n",
    "  \"sculpture\": \"sculpture\",\n",
    "  \"vertical pillar\": \"pillar\",\n",
    "  \"window\": \"window\",\n",
    "}\n",
    "\n",
    "with open(OBJECTS_DB_FILE_PATH, \"r\") as f:\n",
    "  json_data = json.load(f)\n",
    "  img_data = json_data[\"images\"]\n",
    "  obj_data = json_data[\"objects\"]\n",
    "\n",
    "object_count = sorted([(LABEL2LABEL[k], len(a)) for k, a in obj_data.items()], key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for o,c in object_count:\n",
    "  print(o, \":\", c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST: boxes from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from os import path\n",
    "from PIL import Image as PImage, ImageDraw as PImageDraw, ImageFont as PImageFont\n",
    "\n",
    "MFONT = PImageFont.load_default(20)\n",
    "\n",
    "OBJECTS_DB_FILE_PATH = \"./metadata/json/objects.json\"\n",
    "IMAGES_PATH = \"../../imgs/arquigrafia\"\n",
    "\n",
    "with open(OBJECTS_DB_FILE_PATH, \"r\") as f:\n",
    "  json_data = json.load(f)\n",
    "  img_data = json_data[\"images\"]\n",
    "  obj_data = json_data[\"objects\"]\n",
    "\n",
    "for id, d in list(img_data.items())[:3]:\n",
    "  img_path = path.join(IMAGES_PATH, f\"{id}.jpg\")\n",
    "  img = PImage.open(img_path).convert(\"RGBA\")\n",
    "  iw,ih = img.size\n",
    "  draw = PImageDraw.Draw(img)\n",
    "  for label, (x0,y0,x1,y1) in d[\"boxes\"].items():\n",
    "    draw.rectangle(((x0*iw, y0*ih), (x1*iw, y1*ih)), outline=(255, 0, 0), width=2)\n",
    "  print(list(d[\"boxes\"].keys()), \"\\n\", d[\"caption\"])\n",
    "  display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST: Dominant Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from os import listdir, path\n",
    "from PIL import Image as PImage\n",
    "\n",
    "from dominant_colors import get_dominant_colors, resize_PIL\n",
    "\n",
    "IMAGES_IN_PATH = \"../../imgs/arquigrafia\"\n",
    "INPUT_FILES = sorted([f for f in listdir(IMAGES_IN_PATH) if f.endswith(\"jpg\")])\n",
    "\n",
    "io_file = INPUT_FILES[0]\n",
    "input_file_path = path.join(IMAGES_IN_PATH, io_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = PImage.open(input_file_path).convert(\"RGB\")\n",
    "image_s = resize_PIL(image)\n",
    "rgb_by_count, rgb_by_hls = get_dominant_colors(image_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iw, ih = [(d // 2) * 2 for d in image_s.size]\n",
    "image_shape = (ih, iw, 3)\n",
    "ppc = int(ih * iw / len(rgb_by_count))\n",
    "\n",
    "count_np_image = np.array([ppc * [c] for c in rgb_by_count]).reshape(image_shape)\n",
    "hls_np_image = np.array([ppc * [c] for c in rgb_by_hls]).reshape(image_shape)\n",
    "\n",
    "display(image_s)\n",
    "display(PImage.fromarray(count_np_image))\n",
    "display(PImage.fromarray(hls_np_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "\n",
    "from os import path, listdir, makedirs\n",
    "\n",
    "OBJECTS_DB_FILE_PATH = \"./metadata/json/objects.json\"\n",
    "IMAGES_PATH = \"../../imgs\"\n",
    "IMG_IN_DIR = \"arquigrafia\"\n",
    "\n",
    "with open(OBJECTS_DB_FILE_PATH, \"r\") as f:\n",
    "  json_data = json.load(f)\n",
    "  img_data = json_data[\"images\"]\n",
    "  obj_data = json_data[\"objects\"]\n",
    "\n",
    "print(obj_data.keys(), len(obj_data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tocopy = [\n",
    "  'inclined walkway',\n",
    "]\n",
    "\n",
    "for o in tocopy:\n",
    "  print(o, len(obj_data[o]), obj_data[o], \"\\n\")\n",
    "  img_out_dir = f\"test-{o.replace(' ', '-')}\"\n",
    "  img_out_dir_path = path.join(IMAGES_PATH, img_out_dir)\n",
    "  makedirs(img_out_dir_path, exist_ok=True)\n",
    "  for i in obj_data[o]:\n",
    "    img_in_path = path.join(IMAGES_PATH, IMG_IN_DIR, f\"{i}.jpg\")\n",
    "    shutil.copy2(img_in_path, img_out_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PImage, ImageDraw as PImageDraw, ImageFont as PImageFont\n",
    "\n",
    "MFONT = PImageFont.load_default(20)\n",
    "\n",
    "TEST_PATH = \"../../imgs/test-inclined-walkway\"\n",
    "\n",
    "OBJS = {\n",
    "  \"inclined walkway\": 0.41,\n",
    "}\n",
    "\n",
    "LABEL2LABEL = {}\n",
    "\n",
    "OBJS_LABELS_IN = sorted(OBJS.keys())\n",
    "OBJS_LABELS_OUT = [LABEL2LABEL.get(l, l) for l in OBJS_LABELS_IN]\n",
    "OBJS_THOLDS = [OBJS[k] for k in OBJS_LABELS_IN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_object_detection(img, obj_labels_in, obj_labels_out, obj_tholds):\n",
    "  input = obj_processor(text=obj_labels_in, images=img, return_tensors=\"pt\").to(\"cuda\")\n",
    "  with torch.no_grad():\n",
    "    obj_out = obj_model(**input)\n",
    "\n",
    "  res = obj_processor.post_process_object_detection(outputs=obj_out, target_sizes=[OBJ_TARGET_SIZE])\n",
    "  slbs = zip(res[0][\"scores\"], res[0][\"labels\"], res[0][\"boxes\"])\n",
    "  iw, ih = img.size\n",
    "\n",
    "  # filter if box \"too large\" or \"too small\"\n",
    "  def good_thold_and_size(s, l, b):\n",
    "    box_pct = box_px_to_pct(b, iw, ih, OBJ_TARGET_SIZE)\n",
    "    box_width = box_pct[2] - box_pct[0]\n",
    "    box_height = box_pct[3] - box_pct[1]\n",
    "    good_min = box_width > 0.05 and box_height > 0.05\n",
    "    good_max = box_width < 0.8 or box_height < 0.8\n",
    "    return good_min and good_max and s > obj_tholds[l.item()]\n",
    "\n",
    "  detected_objs = [{\"score\": s.item(), \"label\": obj_labels_out[l.item()], \"box\": box_px_to_pct(b, iw, ih, OBJ_TARGET_SIZE)} for s,l,b in slbs if good_thold_and_size(s, l, b)]\n",
    "\n",
    "  # only keep the box with highest score per object\n",
    "  detected_objs_boxes = {}\n",
    "  high_score = {}\n",
    "\n",
    "  for o in detected_objs:\n",
    "    ol = o[\"label\"]\n",
    "    if (ol not in detected_objs_boxes) or (o[\"score\"] > high_score[ol]):\n",
    "      detected_objs_boxes[ol] = o[\"box\"]\n",
    "      high_score[ol] = o[\"score\"]\n",
    "\n",
    "  return detected_objs #detected_objs_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppath = TEST_PATH\n",
    "input_files = sorted([f for f in listdir(ppath) if f.endswith(\"jpg\")])\n",
    "\n",
    "for io_file in input_files:\n",
    "  input_file_path = path.join(ppath, io_file)\n",
    "\n",
    "  image = PImage.open(input_file_path).convert(\"RGB\")\n",
    "  iw,ih = image.size\n",
    "  print(image.size)\n",
    "\n",
    "  objs = run_object_detection(image, OBJS_LABELS_IN, OBJS_LABELS_OUT, OBJS_THOLDS)\n",
    "  print([f'{o[\"label\"]}: {o[\"score\"]}' for o in objs])\n",
    "\n",
    "  draw = PImageDraw.Draw(image)\n",
    "  for o in objs:\n",
    "    (x0,y0,x1,y1) = o[\"box\"]\n",
    "    score, label = o[\"score\"], o[\"label\"]\n",
    "    draw.rectangle(((x0*iw, y0*ih), (x1*iw, y1*ih)), outline=(255, 0, 0), width=2)\n",
    "    draw.text((x0*iw, y0*ih + 20), f\"{round(score, 3)}\", (255, 255, 255), font=MFONT)\n",
    "    draw.text((x0*iw, y0*ih - 0), f\"{label}\", (255, 0, 0), font=MFONT)\n",
    "  display(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
