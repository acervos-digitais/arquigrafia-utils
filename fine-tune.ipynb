{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune DETR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from functools import partial\n",
    "from PIL import Image as PImage, ImageDraw as PImageDraw\n",
    "from pytorch_lightning import Trainer, loggers as PLLoggers\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.transforms import v2 as T\n",
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "\n",
    "from dataset_utils.finetune_0915 import FTUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load HF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"microsoft/conditional-detr-resnet-50\"\n",
    "DATASET_NAME = \"acervos-digitais/ft-0915\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft0915_ds = load_dataset(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ft0915_ds[\"train\"].features[\"objects\"].feature[\"category\"].names\n",
    "\n",
    "id2label = {index: x for index, x in enumerate(categories, start=0)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test HF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = 11\n",
    "image = ft0915_ds[\"train\"][img_id][\"image\"]\n",
    "annotations = ft0915_ds[\"train\"][img_id][\"objects\"]\n",
    "draw = PImageDraw.Draw(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for box,class_idx in zip(annotations[\"bbox\"], annotations[\"category\"]):\n",
    "  x, y, w, h = tuple(box)\n",
    "  x1, y1 = int(x), int(y)\n",
    "  x2, y2 = int(x + w), int(y + h)\n",
    "\n",
    "  draw.rectangle((x, y, x + w, y + h), outline=\"red\", width=1)\n",
    "  draw.text((x+2, y), id2label[class_idx], fill=(0,0,0))\n",
    "  draw.text((x+2, y-12), id2label[class_idx], fill=(255,0,255))\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Image transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = T.Compose([\n",
    "  T.RandomHorizontalFlip(p=0.5),\n",
    "  T.RandomAdjustSharpness(sharpness_factor=2, p=0.5),\n",
    "  T.RandomEqualize(p=0.5),\n",
    "  T.RandomPerspective(distortion_scale=0.6, p=0.5),\n",
    "  T.RandomApply(transforms=[T.RandomRotation(degrees=35)], p=0.5),\n",
    "  T.RandomApply(transforms=[T.RandomAffine(degrees=0, translate=(0.15, 0.15), scale=(0.8, 1.25))], p=0.5),\n",
    "  T.RandomApply(transforms=[T.ColorJitter(brightness=0.5, hue=0.3)], p=0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_batch(examples, transform, image_processor, return_pixel_mask=False):\n",
    "  images = []\n",
    "  annotations = []\n",
    "  for image_id, image, objects in zip(examples[\"image_id\"], examples[\"image\"], examples[\"objects\"]):\n",
    "    iw, ih = image.size\n",
    "    objects[\"bbox\"] = tv_tensors.BoundingBoxes(objects[\"bbox\"], format=\"XYWH\", canvas_size=(ih, iw))\n",
    "    image = tv_tensors.Image(image.convert(\"RGB\"))\n",
    "\n",
    "    # apply augmentations\n",
    "    if transform is not None:\n",
    "      image, bboxes, categories = transform(image, objects[\"bbox\"], objects[\"category\"])\n",
    "      objects[\"bbox\"] = bboxes\n",
    "      objects[\"category\"] = categories\n",
    "\n",
    "    images.append(image)\n",
    "\n",
    "    # format annotations in COCO format\n",
    "    formatted_annotations = FTUtils.as_coco(image_id, objects)\n",
    "    annotations.append(formatted_annotations)\n",
    "\n",
    "  # Apply the image processor transformations: resizing, rescaling, normalization\n",
    "  result = image_processor(images=images, annotations=annotations, return_tensors=\"pt\")\n",
    "\n",
    "  if not return_pixel_mask:\n",
    "    result.pop(\"pixel_mask\", None)\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Image transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr_processor = AutoImageProcessor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "train_transform = partial(transform_batch, transform=image_transform, image_processor=detr_processor, return_pixel_mask=True)\n",
    "validation_transform = partial(transform_batch, transform=None, image_processor=detr_processor, return_pixel_mask=True)\n",
    "\n",
    "train_ds = ft0915_ds[\"train\"].with_transform(train_transform)\n",
    "val_ds = ft0915_ds[\"test\"].with_transform(validation_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "  data = {}\n",
    "  data[\"pixel_values\"] = torch.stack([x[\"pixel_values\"] for x in batch])\n",
    "  data[\"labels\"] = [x[\"labels\"] for x in batch]\n",
    "  if \"pixel_mask\" in batch[0]:\n",
    "    data[\"pixel_mask\"] = torch.stack([x[\"pixel_mask\"] for x in batch])\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds, collate_fn=collate_fn, batch_size=4, num_workers=4, shuffle=True)\n",
    "val_dataloader = DataLoader(val_ds, collate_fn=collate_fn, batch_size=4, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_detr(model, processor, dataset, min_threshold=0.2, thresholds=[]):\n",
    "  num_correct = 0\n",
    "  num_preds = 0\n",
    "  num_labels = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for row in dataset:\n",
    "      img = row[\"image\"]\n",
    "      iw, ih = img.size\n",
    "\n",
    "      inputs = processor(images=img, return_tensors=\"pt\")\n",
    "      pixel_values = inputs[\"pixel_values\"].to(\"cuda\")\n",
    "\n",
    "      outputs = model(pixel_values=pixel_values, pixel_mask=None)\n",
    "\n",
    "      ppo = processor.post_process_object_detection(outputs,\n",
    "                                                    target_sizes=[(ih, iw)],\n",
    "                                                    threshold=min_threshold)[0]\n",
    "\n",
    "      preds = [l.item() for l in ppo[\"labels\"]]\n",
    "      scores = [s.item() for s in ppo[\"scores\"]]\n",
    "      boxes = [b.tolist() for b in ppo[\"boxes\"]]\n",
    "\n",
    "      if len(thresholds) > 0:\n",
    "        f_preds = []\n",
    "        f_scores = []\n",
    "        f_boxes = []\n",
    "\n",
    "        for p,s,b in zip(preds, scores, boxes):\n",
    "          if s > thresholds[p]:\n",
    "            f_preds.append(p)\n",
    "            f_scores.append(s)\n",
    "            f_boxes.append(b)\n",
    "\n",
    "        preds, scores, boxes = f_preds, f_scores, f_boxes\n",
    "\n",
    "      labels = row[\"objects\"][\"category\"]\n",
    "\n",
    "      cpreds = [1 for p in set(preds) if p in labels]\n",
    "\n",
    "      num_correct += len(cpreds)\n",
    "      num_preds += len(preds)\n",
    "      num_labels += len(labels)\n",
    "  \n",
    "  precision = round(num_correct / num_preds, 4) if num_preds != 0 else 0\n",
    "  recall = round(num_correct / num_labels, 4) if num_labels != 0 else 0\n",
    "  return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detr(pl.LightningModule):\n",
    "  def __init__(self, model_name, image_processor, lr, lr_backbone, weight_decay):\n",
    "    super().__init__()\n",
    "    self.processor = image_processor\n",
    "    self.model = AutoModelForObjectDetection.from_pretrained(\n",
    "      model_name,\n",
    "      id2label=id2label,\n",
    "      label2id=label2id,\n",
    "      ignore_mismatched_sizes=True\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # see https://github.com/PyTorchLightning/pytorch-lightning/pull/1896\n",
    "    self.lr = lr\n",
    "    self.lr_backbone = lr_backbone\n",
    "    self.weight_decay = weight_decay\n",
    "    self.save_hyperparameters()\n",
    "\n",
    "  def forward(self, pixel_values, pixel_mask):\n",
    "    return self.model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
    "\n",
    "  def common_step(self, batch, batch_idx):\n",
    "    pixel_values = batch[\"pixel_values\"]\n",
    "    pixel_mask = batch[\"pixel_mask\"]\n",
    "    labels = [{k: v.to(self.device) for k,v in t.items()} for t in batch[\"labels\"]]\n",
    "\n",
    "    outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)\n",
    "\n",
    "    loss = outputs.loss\n",
    "    loss_dict = outputs.loss_dict\n",
    "\n",
    "    return loss, loss_dict\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    loss, loss_dict = self.common_step(batch, batch_idx)\n",
    "    self.log(\"training_loss\", loss)\n",
    "    for k,v in loss_dict.items():\n",
    "      self.log(\"train_\" + k, v.item())\n",
    "\n",
    "    if batch_idx == 0:\n",
    "      precision, recall = eval_detr(self.model, self.processor, ft0915_ds[\"train\"])\n",
    "      self.log(\"train_precision\", precision)\n",
    "      self.log(\"train_recall\", recall)\n",
    "\n",
    "    return loss\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    loss, loss_dict = self.common_step(batch, batch_idx)\n",
    "    self.log(\"validation_loss\", loss)\n",
    "    for k,v in loss_dict.items():\n",
    "      self.log(\"validation_\" + k, v.item())\n",
    "\n",
    "    if batch_idx == 0:\n",
    "      precision, recall = eval_detr(self.model, self.processor, ft0915_ds[\"test\"])\n",
    "      self.log(\"validation_precision\", precision)\n",
    "      self.log(\"validation_recall\", recall)\n",
    "\n",
    "    return loss\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    param_dicts = [\n",
    "          {\"params\": [p for n,p in self.named_parameters() if \"backbone\" not in n and p.requires_grad]},\n",
    "          {\n",
    "              \"params\": [p for n,p in self.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
    "              \"lr\": self.lr_backbone,\n",
    "          },\n",
    "    ]\n",
    "    optimizer = torch.optim.AdamW(param_dicts, lr=self.lr, weight_decay=self.weight_decay)\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    return train_dataloader\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    return val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  del model\n",
    "except:\n",
    "  pass\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Detr(model_name=MODEL_NAME, image_processor=detr_processor,\n",
    "             lr=1e-5, lr_backbone=1e-5, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = torch.load(\"lightning_logs/76+43e-1e-5lr-augm3/checkpoints/epoch=43-step=3300.ckpt\")\n",
    "model.load_state_dict(cp[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mLogger = PLLoggers.TensorBoardLogger(save_dir=\".\", version=\"e256-augm3\")\n",
    "trainer = Trainer(accelerator=\"gpu\", max_epochs=256, gradient_clip_val=0.1, logger=mLogger)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to HF Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_MODEL_NAME = \"acervos-digitais/conditional-detr-resnet-50-ft-0915-e256-augm3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.push_to_hub(OUTPUT_MODEL_NAME)\n",
    "detr_processor.push_to_hub(OUTPUT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from os import path\n",
    "from PIL import Image as PImage, ImageDraw as PImageDraw, ImageFont as PImageFont\n",
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "\n",
    "from dataset_utils.finetune_0915 import FTUtils\n",
    "\n",
    "MODEL_NAME = OUTPUT_MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft0915_ds = load_dataset(\"acervos-digitais/ft-0915\")\n",
    "\n",
    "detr_processor = AutoImageProcessor.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForObjectDetection.from_pretrained(\n",
    "  MODEL_NAME,\n",
    "  id2label=FTUtils.ID2LABEL,\n",
    "  label2id=FTUtils.LABEL2ID,\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_detr(model, detr_processor, list(ft0915_ds[\"train\"]), min_threshold=0.3, thresholds=[]))\n",
    "print(eval_detr(model, detr_processor, list(ft0915_ds[\"test\"]), min_threshold=0.3, thresholds=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.27, 0.27, 0.55]\n",
    "print(eval_detr(model, detr_processor, list(ft0915_ds[\"train\"]), min_threshold=0.15, thresholds=thresholds))\n",
    "print(eval_detr(model, detr_processor, list(ft0915_ds[\"test\"]), min_threshold=0.15, thresholds=thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.27, 0.27, 0.55]\n",
    "print(eval_detr(model, detr_processor, list(ft0915_ds[\"train\"]), min_threshold=0.15, thresholds=thresholds))\n",
    "print(eval_detr(model, detr_processor, list(ft0915_ds[\"test\"]), min_threshold=0.15, thresholds=thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.26, 0.26, 0.74]\n",
    "print(eval_detr(model, detr_processor, list(ft0915_ds[\"train\"]), min_threshold=0.15, thresholds=thresholds))\n",
    "print(eval_detr(model, detr_processor, list(ft0915_ds[\"test\"]), min_threshold=0.15, thresholds=thresholds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in list(ft0915_ds[\"test\"])[:48]:\n",
    "  img = r[\"image\"]\n",
    "  iw, ih = img.size\n",
    "  draw = PImageDraw.Draw(img)\n",
    "\n",
    "  inputs = detr_processor(images=img, return_tensors=\"pt\")\n",
    "  pixel_values = inputs[\"pixel_values\"].to(\"cuda\")\n",
    "\n",
    "  with torch.no_grad():\n",
    "    outputs = model(pixel_values=pixel_values, pixel_mask=None)\n",
    "\n",
    "  ppo = detr_processor.post_process_object_detection(outputs,\n",
    "                                                     target_sizes=[(ih, iw)],\n",
    "                                                     threshold=0.25)[0]\n",
    "\n",
    "  labels_list = [l.item() for l in ppo[\"labels\"]]\n",
    "  scores_list = [round(s.item(),4) for s in ppo[\"scores\"]]\n",
    "\n",
    "  print(\"pred:\", [(FTUtils.ID2LABEL[l],s) for l,s in zip(labels_list, scores_list)])\n",
    "  print(\"labels:\", [FTUtils.ID2LABEL[c] for c in r[\"objects\"][\"category\"]])\n",
    "\n",
    "  for l,b,s in zip(ppo[\"labels\"], ppo[\"boxes\"], ppo[\"scores\"]):\n",
    "    draw.rectangle(((b[0], b[1]), (b[2], b[3])), outline=(255, 0, 0), width=2)\n",
    "\n",
    "  display(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
